{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Chatbot Agent in LangGraph\n",
    "\n",
    "In this tutorial, we will build a support chatbot using LangGraph. We will implement this chatbot via a graph workflow using nodes and edges.\n",
    "\n",
    "The chatbot will:\n",
    "\n",
    "- Answer common questions by searching the web.\n",
    "- Use custom tools to enhance its capabilities.\n",
    "- Maintain conversation state across calls.\n",
    "\n",
    "This tutorial builds the foundation for more complex workflows and design patterns later in the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "We start by importing the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "from datetime import datetime\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Model\n",
    "Initialize the language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Tools\n",
    "We will define two tools:\n",
    "\n",
    "- Tavily Search Tool: To fetch relevant information from the web.\n",
    "- Current Date and Time Tool: Helps the chatbot respond to time-based queries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tavily Search Tool\n",
    "tavily_search = TavilySearchResults(max_results=2)\n",
    "\n",
    "# Current Date and Time Tool\n",
    "@tool\n",
    "def get_current_date():\n",
    "    \"\"\"Returns the current date and time. Use this tool first for any time-based queries.\"\"\"\n",
    "    return f\"The current date is: {datetime.now().strftime('%d %B %Y')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of tools for the agent\n",
    "tools = [tavily_search, get_current_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binding Tools to the LLM\n",
    "We bind the tools to the language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the StateGraph\n",
    "We define the state of our chatbot using StateGraph. The State consists of a messages list, which will store the conversation history.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Graph Nodes\n",
    "We define a chatbot node, which represents the LLM's response generation. We also define a tool node to handle tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10f429910>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10f429910>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Graph Edges\n",
    "We define how the chatbot transitions between nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10f429910>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conditional edge to decide whether to use tools, this is a prebuilt conditional edge\n",
    "graph_builder.add_conditional_edges(\"chatbot\", tools_condition)\n",
    "\n",
    "# If tools are used, return to the chatbot to process the tool output\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "# Set the entry point of the graph\n",
    "graph_builder.set_entry_point(\"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the Graph\n",
    "We compile the graph to create a runnable chatbot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "### Visualizing the Chatbot's Workflow\n",
    "We can visualize the chatbot's workflow using LangGraph's graph visualization tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "# Visualize the chatbot's workflow\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    pass  # Visualization requires additional dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Chatbot\n",
    "Now, we can interact with our chatbot.\n",
    "\n",
    "#### Helper Functions\n",
    "We define helper functions to process and render the chatbot's responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "def render_markdown(md_string):\n",
    "    display(Markdown(md_string))\n",
    "\n",
    "def process_stream(stream):\n",
    "    for s in stream:\n",
    "        message = s[\"messages\"][-1]\n",
    "        if isinstance(message, tuple):\n",
    "            print(message)\n",
    "        else:\n",
    "            message.pretty_print()\n",
    "    return message\n",
    "\n",
    "def process_query(query, config=None):\n",
    "    inputs = {\"messages\": [(\"user\", query)]}\n",
    "    message = process_stream(graph.stream(inputs, config, stream_mode=\"values\"))\n",
    "    render_markdown(f\"## Answer:\\n{message.content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the Chatbot\n",
    "We can now test the chatbot with various queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello! What can you do?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(64751) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello! I can assist with a variety of tasks, including:\n",
      "\n",
      "- Answering questions and providing information on a wide range of topics.\n",
      "- Conducting searches for current events or specific queries.\n",
      "- Providing the current date and time.\n",
      "- Offering explanations, summaries, and recommendations.\n",
      "- Assisting with problem-solving and decision-making.\n",
      "\n",
      "If you have any specific questions or tasks, feel free to ask!\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Answer:\n",
       "Hello! I can assist with a variety of tasks, including:\n",
       "\n",
       "- Answering questions and providing information on a wide range of topics.\n",
       "- Conducting searches for current events or specific queries.\n",
       "- Providing the current date and time.\n",
       "- Offering explanations, summaries, and recommendations.\n",
       "- Assisting with problem-solving and decision-making.\n",
       "\n",
       "If you have any specific questions or tasks, feel free to ask!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "process_query(\"Hello! What can you do?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the current date?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_current_date (call_NRLRfT9OgaVTBzabfAbyMHcL)\n",
      " Call ID: call_NRLRfT9OgaVTBzabfAbyMHcL\n",
      "  Args:\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_current_date\n",
      "\n",
      "The current date is: 04 April 2025\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Today's date is April 4, 2025.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Answer:\n",
       "Today's date is April 4, 2025."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Query that requires current date\n",
    "process_query(\"What is the current date?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is LangGraph?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (call_3G3IgCyN5oDRXsJDGFDhKH0m)\n",
      " Call ID: call_3G3IgCyN5oDRXsJDGFDhKH0m\n",
      "  Args:\n",
      "    query: LangGraph\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://langchain-ai.github.io/langgraph/tutorials/introduction/\", \"content\": \"[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-9-1)Assistant: LangGraph is a library designed to help build stateful multi-agent applications using language models. It provides tools for creating workflows and state machines to coordinate multiple AI agents or language model interactions. LangGraph is built on top of LangChain, leveraging its components while adding graph-based coordination capabilities. It's particularly useful for developing more complex, [...] [](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-6)   LangGraph is a library designed for building stateful, multi-actor applications with Large Language Models (LLMs). It's particularly useful for creating agent and multi-agent workflows.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-8)2. Developer: [...] [](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-19)LangGraph is likely a framework or library designed specifically for creating AI agents with advanced capabilities. Here are a few points to consider based on this recommendation:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-20)\"}, {\"url\": \"https://realpython.com/langgraph-python/\", \"content\": \"Remove ads\\nLangGraph is a versatile Python library designed for stateful, cyclic, and multi-actor Large Language Model (LLM) applications. LangGraph builds upon its parent library, LangChain, and allows you to build sophisticated workflows that are capable of handling the complexities of real-world LLM applications.\\nBy the end of this tutorial, you’ll understand that: [...] These FAQs are related to the most important concepts you’ve covered in this tutorial. Click the Show/Hide toggle beside each question to reveal the answer.\\nWhat is LangGraph?Show/Hide\\nLangGraph is a Python library that helps you build stateful, cyclic, and multi-actor workflows for Large Language Model (LLM) applications, expanding upon LangChain’s capabilities.\\nHow does LangGraph differ from LangChain?Show/Hide [...] As you might have inferred from the name, LangGraph is all about implementing LLM applications as directed graphs. You can think of a directed graph as a sequence of instructions composed of nodes and edges, that tell you how to complete a task. In LangGraph, nodes represent actions that your graph can take, such as calling a function, and edges tell you which node to go to next.\\nTo understand this better, take a look at this directed graph:\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph is a Python library designed to build stateful, cyclic, and multi-actor applications using Large Language Models (LLMs). It is an extension of LangChain, providing tools for creating sophisticated workflows and state machines that facilitate the coordination of multiple AI agents or interactions with language models. LangGraph is particularly useful for developing complex applications by implementing them as directed graphs, where nodes represent actions (such as calling a function) and edges dictate the flow between these actions.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Answer:\n",
       "LangGraph is a Python library designed to build stateful, cyclic, and multi-actor applications using Large Language Models (LLMs). It is an extension of LangChain, providing tools for creating sophisticated workflows and state machines that facilitate the coordination of multiple AI agents or interactions with language models. LangGraph is particularly useful for developing complex applications by implementing them as directed graphs, where nodes represent actions (such as calling a function) and edges dictate the flow between these actions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Query that triggers the Tavily search tool\n",
    "process_query(\"What is LangGraph?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "When is the next olympics?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_current_date (call_DVRbhrLXNfuh5MQP2TUwdR2q)\n",
      " Call ID: call_DVRbhrLXNfuh5MQP2TUwdR2q\n",
      "  Args:\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_current_date\n",
      "\n",
      "The current date is: 04 April 2025\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (call_4TkSpy4UCbW5RxJLT4eFmLOQ)\n",
      " Call ID: call_4TkSpy4UCbW5RxJLT4eFmLOQ\n",
      "  Args:\n",
      "    query: next Olympic Games date 2025\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://en.wikipedia.org/wiki/2026_Winter_Olympics\", \"content\": \"^ \\\"Milano Cortina 2026 and the Olympic Torch: A journey without equal\\\". Inside the Games. 27 November 2024. Archived from the original on 27 November 2024. Retrieved 3 February 2025.\\n^ \\\"Piling work to start on ice hockey venue for Milan Cortina 2026\\\". Inside the Games. 4 June 2023. Archived from the original on 20 July 2024. Retrieved 30 January 2025. [...] ^ Robinson, Joshua (18 December 2024). \\\"The Milan Olympics Has a Backup Location. It's in Upstate New York\\\". The Wall Street Journal. Archived from the original on 20 December 2024. Retrieved 13 January 2025.\\n^ \\\"Sliding venue for Milano-Cortina 2026 Games to have first tests in March, says IOC\\\". Reuters. 4 December 2024. Archived from the original on 4 December 2024. Retrieved 13 January 2025. [...] ^ \\\"Olympic Winter Games, Women's Ice Hockey Tournament\\\". IIHF.com. Retrieved 24 February 2025.\\n^ \\\"Competition Schedule V.5 (by session)\\\" (PDF). www./milanocortina2026.olympics.com. Milano-Cortina Organising Committee for the 2026 Olympic and Paralympic Winter Games. 13 March 2024. Archived (PDF) from the original on 16 July 2024. Retrieved 10 September 2024.\"}, {\"url\": \"https://www.cbsnews.com/news/next-olympic-locations/\", \"content\": \"CBS News Investigates\\nCBS Village\\nPodcasts\\nIn Depth\\nNewsletters\\nDownload Our App\\nCBS News Team\\nExecutive Team\\nBrand Studio\\nParamount+\\nJoin Our Talent Community\\nRSS Feeds\\nDavos Interviews\\nA Moment With...\\nInnovators & Disruptors\\nEconomy 4.0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nU.S.\\nSuper Bowl 2025\\nWorld\\nPolitics\\nHealthWatch\\nMoneyWatch\\nEntertainment\\nCrime\\nSports\\n\\n\\nWatch CBS News\\nWorld\\nSee the next Olympics locations for 2026, 2028 and more future games\\nBy Aliza Chasan\\nUpdated on: July 26, 2024 / 3:03 PM EDT / CBS News\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The next Olympic Games will be the 2026 Winter Olympics, which will take place in Milan-Cortina, Italy.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Answer:\n",
       "The next Olympic Games will be the 2026 Winter Olympics, which will take place in Milan-Cortina, Italy."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Time-based query about an event\n",
    "process_query(\"When is the next olympics?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need for Memory\n",
    "\n",
    "Taking a look at an example of where the current chatbot falls short when remembering previous interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi. My name is Sajal. Who are you?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Sajal! I'm an AI assistant designed to help you with a variety of tasks and answer your questions. How can I assist you today?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Answer:\n",
       "Hello Sajal! I'm an AI assistant designed to help you with a variety of tasks and answer your questions. How can I assist you today?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "process_query(\"Hi. My name is Sajal. Who are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'm sorry, but I don't have access to personal data about individuals unless it has been shared with me in the course of our conversation. If you've mentioned your name earlier, I don't have the capability to recall it. Let me know if there's anything else I can assist you with!\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Answer:\n",
       "I'm sorry, but I don't have access to personal data about individuals unless it has been shared with me in the course of our conversation. If you've mentioned your name earlier, I don't have the capability to recall it. Let me know if there's anything else I can assist you with!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "process_query(\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Memory to the Chatbot\n",
    "To maintain conversation state across calls, we use LangGraph's checkpointing system.\n",
    "\n",
    "#### Setting Up Checkpointing\n",
    "We create a MemorySaver checkpointer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the graph with the checkpointer\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Thread IDs for Conversation State\n",
    "We can maintain separate conversation threads by providing a thread_id in the configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi. My name is Sajal. Who are you?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Sajal! I'm an AI assistant here to help you with information, answer questions, and assist with a variety of tasks. How can I assist you today?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Answer:\n",
       "Hello Sajal! I'm an AI assistant here to help you with information, answer questions, and assist with a variety of tasks. How can I assist you today?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config_user_1 = {\"thread_id\": \"user_1\"}\n",
    "process_query(\"Hi. My name is Sajal. Who are you?\", config=config_user_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Sajal.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Answer:\n",
       "Your name is Sajal."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "process_query(\"What is my name?\", config=config_user_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'm sorry, but I don't have access to personal data about individuals unless it has been shared with me in the course of our conversation. Therefore, I don't know your name. If you'd like, you can tell me your name.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Answer:\n",
       "I'm sorry, but I don't have access to personal data about individuals unless it has been shared with me in the course of our conversation. Therefore, I don't know your name. If you'd like, you can tell me your name."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking if memory is shared across threads\n",
    "config_user_2 = {\"thread_id\": \"user_2\"}\n",
    "process_query(\"What is my name?\", config=config_user_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Who is Donald Trump?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Donald Trump is an American businessman, television personality, and politician who served as the 45th President of the United States from January 20, 2017, to January 20, 2021. Before his presidency, he was known for his real estate business, primarily through his company, The Trump Organization, and for hosting the reality TV show \"The Apprentice.\"\n",
      "\n",
      "Trump is a member of the Republican Party and has been a prominent and often controversial figure in American politics and media. His presidency was marked by significant policy changes, a focus on \"America First\" initiatives, and a divisive style of communication. After his presidency, he has remained an influential figure in American politics.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Answer:\n",
       "Donald Trump is an American businessman, television personality, and politician who served as the 45th President of the United States from January 20, 2017, to January 20, 2021. Before his presidency, he was known for his real estate business, primarily through his company, The Trump Organization, and for hosting the reality TV show \"The Apprentice.\"\n",
       "\n",
       "Trump is a member of the Republican Party and has been a prominent and often controversial figure in American politics and media. His presidency was marked by significant policy changes, a focus on \"America First\" initiatives, and a divisive style of communication. After his presidency, he has remained an influential figure in American politics."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Time-based query about an event\n",
    "process_query(\"Who is Donald Trump?\", config=config_user_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "\n",
    "Congratulations on building your own chatbot agent from scratch with LangGraph. Be sure to go through the next few tutorials to learn more about adding human in the loop capabilities to this agent!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
